{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21f8cd8-6f52-4309-abdc-25240735ca63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import pickle\n",
    "from Bio import Entrez\n",
    "import pandas as pd\n",
    "import os\n",
    "from openai import OpenAI, RateLimitError, APIError, OpenAIError\n",
    "import json\n",
    "import numpy as np\n",
    "import xml\n",
    "from xml.dom.minidom import Document\n",
    "import copy\n",
    "import tiktoken\n",
    "import time\n",
    "import re\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "from bs4 import BeautifulSoup\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed01eb1f-bfe0-4755-9040-fe7461ce3a76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", 100)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21540d30-7477-415e-bd5f-ee9bd1fb5e23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    client = OpenAI(\n",
    "        api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "        organization='',\n",
    "        project='',\n",
    "    )\n",
    "except:\n",
    "    print('Something goes wrong on the connection with chatGPT.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba01819-f411-4ed0-af85-945dcdf4953b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def requisition_chat(gpt_model, prompt):\n",
    "    \"\"\"\n",
    "    This function communicates with the chatGPT API. It sends a input and returns the model's output.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "        model=gpt_model,        \n",
    "        response_format = {\"type\":\"json_object\"},\n",
    "        messages=[\n",
    "        {\"role\": \"system\", \"content\": prompt}    \n",
    "        ]\n",
    "        )\n",
    "    except RateLimitError as e:\n",
    "        print(\"Rate limit exceeded. Retrying after a delay...\")\n",
    "        time.sleep(60)  # Wait for 10 seconds before retrying\n",
    "        return requisition_chat(gpt_model, prompt)    \n",
    "    except APIError as e:\n",
    "        print(f\"API error: {e}\")  \n",
    "        return False\n",
    "    except OpenAIError as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        time.sleep(5)  # Wait for 5 seconds before retrying        \n",
    "        return requisition_chat(gpt_model, prompt)\n",
    "    \n",
    "    return completion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226852c2-9e3e-4a67-9935-eadbee2864ac",
   "metadata": {},
   "source": [
    "### General settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9792718d-c81e-4abf-99b8-078851ff0d3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "research_question = \"What is the diagnostic accuracy of the no-biopsy approach (10- fold increase in serum IgA antitissue transglutaminase (tTG) antibody levels) for the diagnosis of coeliac disease in adults?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55eef110-c0a0-47ac-89ed-8bcdb24f860c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "models = ['gpt-3.5-turbo', 'gpt-4', 'gpt-4o-mini', 'gpt-4o', 'text-davinci-003', 'gpt-4-turbo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcb3029-b799-4508-8a64-ed4424981c30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gpt_model = models[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47ed643-36ab-49f8-80e5-48aab310f38c",
   "metadata": {},
   "source": [
    "### Getting a list of keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a23f8b9-712a-42d7-89ab-ff7e3425f1e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_keywords = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2368ec39-5d05-4549-8311-63402793a36e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "json_schema_search_s = {\"keywords\": [\"\", \"\", \"\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3152d46-6643-40da-b204-fc72bb3a1d51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = f'You are a researcher conducting a systematic review to answer the following research question: {research_question} \\\n",
    "You need to provide {n_keywords} specific keywords that can be used in an in-depth and extensive PubMed search. \\\n",
    "Please provide a comprehensive search string using JSON format with no additional description or context. \\\n",
    "The data schema should be like this: ' + json.dumps(json_schema_search_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc075966-803c-4785-881a-4eae426e3b83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_k = requisition_chat(gpt_model, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc026b61-a76f-4b3b-8346-5e56762677c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "search_k = output_k.choices[0].message.content\n",
    "search_k = json.loads(search_k)\n",
    "search_k = search_k['keywords']\n",
    "search_k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418bcd3e-4602-4ffc-9ac4-92e579db96f2",
   "metadata": {},
   "source": [
    "### Getting inclusion and exclusion criteria on chatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc7b7ed-8af5-4f6f-b967-365280839c44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "json_schema_criteria = {\"inclusion_criteria\": [{\"type\":\"population\", \"criteria\":\"...\"}], \"exclusion_criteria\":[{\"type\":\"population\", \"criteria\":\"...\"}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ae535d-d61f-4ab9-ab34-8a78e243d97f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = f'You are a researcher conducting a systematic review to answer the following research question: \"{research_question}\" \\\n",
    "Now, you need to provide inclusion and exclusion criterias based on the research question. These criterias \\\n",
    "will be used to screening papers and define the ones that shold be included on the review. Use JSON format with no additional description or context. \\\n",
    "The data schema should be like this: {json_schema_criteria}'\n",
    "\n",
    "output_criteria = requisition_chat(gpt_model, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f346eeae-ff8b-44aa-8a61-2e19c26407b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# it checks if the requisition received the response correctly\n",
    "if output_criteria.choices[0].finish_reason == 'stop':\n",
    "    response = output_criteria.choices[0].message.content\n",
    "    response = json.loads(response)\n",
    "    inclusion_criteria_dicts = response['inclusion_criteria']\n",
    "    exclusion_criteria_dicts = response['exclusion_criteria']\n",
    "else:\n",
    "    print(\"The response of the model is not complete. Reason:\", output_criteria.choices[0].finish_reason)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6eb872-16fd-457a-82df-11b57368e879",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "get_criterias = lambda criteria_dict: criteria_dict['criteria']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cb695a-b43a-4397-93fe-4271bf6d0a02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exclusion_criteria_list = list(map(get_criterias, exclusion_criteria_dicts))\n",
    "inclusion_criteria_list = list(map(get_criterias, inclusion_criteria_dicts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0467176a-2e11-49f4-a315-46f2ea20ca77",
   "metadata": {},
   "source": [
    "### Constructing the dataset on PubMed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94d319f-c0b6-4606-9d93-51614a790ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your email here\n",
    "Entrez.email = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5bf9b9-1c7e-4e8f-b173-22e031ee017d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_pubmed(query, max_results=10):\n",
    "    handle = Entrez.esearch(db=\"pubmed\", term=query, retmax=max_results)\n",
    "    record = Entrez.read(handle)\n",
    "    handle.close()\n",
    "    return record[\"IdList\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5331b1b-678a-4a2b-96f8-516dcb836c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_details(id_list):\n",
    "    ids = \",\".join(id_list)\n",
    "    handle = Entrez.efetch(db=\"pubmed\", id=ids, rettype=\"medline\", retmode=\"xml\")\n",
    "    records = Entrez.read(handle)\n",
    "    handle.close()\n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f40b8a-5364-4b01-b49e-1a0c1a7b2a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_records(records):\n",
    "    articles = []        \n",
    "    for record in records['PubmedArticle']:        \n",
    "        article = {}\n",
    "        article['PMID'] = record['MedlineCitation']['PMID']\n",
    "        article['Keywords'] = record['MedlineCitation']['KeywordList'][0] if len(record['MedlineCitation']['KeywordList']) > 0 else 'No keyword list available'\n",
    "        article['Country'] = record['MedlineCitation']['MedlineJournalInfo']['Country']\n",
    "        article['Language'] = record['MedlineCitation']['Article']['Language'][0]        \n",
    "        article['Title'] = record['MedlineCitation']['Article']['ArticleTitle']\n",
    "        article['Abstract'] = record['MedlineCitation']['Article']['Abstract']['AbstractText'][0] if 'Abstract' in record['MedlineCitation']['Article'] else 'No abstract available'\n",
    "        article['Journal'] = record['MedlineCitation']['Article']['Journal']['Title']\n",
    "        article['PubYear'] = record['MedlineCitation']['Article']['Journal']['JournalIssue']['PubDate'].get('Year', 'No date available')\n",
    "        article['ISSN'] = record['MedlineCitation']['Article']['Journal']['ISSN'] if 'ISSN' in record['MedlineCitation']['Article']['Journal'] else 'No ISSN available'\n",
    "        articles.append(article)\n",
    "    return articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f97d284-780a-4129-a7a5-6a811c5f3837",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pubmed(search_):\n",
    "    id_list = search_pubmed(search_, max_results=20000)\n",
    "    if not id_list:\n",
    "        print(\"No articles found.\")\n",
    "        return\n",
    "    \n",
    "    records = fetch_details(id_list)\n",
    "    \n",
    "    articles = parse_records(records)\n",
    "    \n",
    "    df = pd.DataFrame(articles)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1e574c-b49b-486a-b794-0ca30681981e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(search_, type_search='search_string'):\n",
    "    if type_search=='search_string':\n",
    "        df = pubmed(search_)\n",
    "    elif type_search=='keywords':\n",
    "        df = pd.DataFrame()\n",
    "        a = 0\n",
    "        for keyword in search_:\n",
    "            aux = pubmed(keyword)\n",
    "            a += len(aux)\n",
    "            df = pd.concat([df, aux], axis = 0)\n",
    "                                        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6586db91-f264-46b3-9d18-30cf229cad80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = main(search_k[:3], 'keywords')\n",
    "df2 = main(search_k[3:6], 'keywords')\n",
    "df3 = main(search_k[6:9], 'keywords')\n",
    "df4 = main(search_k[9:12], 'keywords')\n",
    "df5 = main(search_k[12:15], 'keywords')\n",
    "df6 = main(search_k[15:18], 'keywords')\n",
    "df7 = main(search_k[18:], 'keywords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde0cc99-31a3-40f1-9646-54e5611e4310",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df1, df2, df3, df4, df5, df6, df7], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa96111-40af-4ba6-bbe5-b5fa5be32a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('df_papers.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6066bfe6-65a1-48ef-980f-e34090571127",
   "metadata": {},
   "source": [
    "### Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da85644-8386-4ded-bd30-ebc5fca60ce9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('df_papers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aad6099-7b50-49c2-b533-9978f4850b03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Drop duplicates rows\n",
    "\n",
    "df = df.drop_duplicates(subset=['PMID'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba343ad-c5ff-4c7a-bd21-4d3ebffa0cc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# maintaning just english papers\n",
    "\n",
    "df = df[df.Language == 'eng']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9e7c04-47bf-438d-9612-754c31095283",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd36e1a6-13af-4805-bbc0-beb5597dbcf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    # Remove Markdown links\n",
    "    text = re.sub(r'\\[.*?\\]\\(.*?\\)', '', text)\n",
    "    # Remove Markdown bold and italic\n",
    "    text = re.sub(r'\\*\\*|__', '', text)  # bold\n",
    "    text = re.sub(r'\\*|_', '', text)  # italic\n",
    "    # Remove inline code\n",
    "    text = re.sub(r'`.*?`', '', text)\n",
    "    return text\n",
    "\n",
    "# Apply the function to the DataFrame\n",
    "df['Title'] = df['Title'].apply(clean_text)\n",
    "df['Abstract'] = df['Abstract'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c46c1f-7af1-4761-8938-b9f22b65f6e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['Title'] = df['Title'].str.lower()\n",
    "df['Title'] = df['Title'].str.rstrip('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b26e5f-ca49-4bcc-beb6-1c9afe1c3ad6",
   "metadata": {},
   "source": [
    "## First Screening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea642a2-237b-4f96-87d0-001573026d50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "quant_papers = 1000\n",
    "batch_size = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79594d7-6b18-4b30-9b04-21f52a9c1156",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "json_schema_1st = {'gpt_decision': [{'Title':'', 'Decision':'include', 'Reason': ''}, {'Title':'', 'Decision':'exclude', 'Reason': ''}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff1ffb3-0f5d-424b-b2dc-6dc85b28ec29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "array_title = np.array(df.Title)\n",
    "array_abstract = np.array(df.Abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a1a5a1-d2ef-4737-97f8-303d27d1231d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "messages = []\n",
    "\n",
    "for i in range(0, quant_papers):    \n",
    "    a = \"Title: \" + array_title[i] + \"\\n Abstract: \" + array_abstract[i]        \n",
    "    messages.append(a)\n",
    "\n",
    "messages = np.array(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162aff0e-f821-492a-bd6a-008041aca776",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "responses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36c06a6-c5c7-443d-b218-6d443833fb66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a single prompt with all messages in the batch\n",
    "prompt = f\"You are a researcher conducting a systematic review to answer the following research question: {research_question} \\\n",
    "You need to screen the papers' titles and abstracts and decide whether each paper should be included or excluded in the research using exclusion criteria. \\\n",
    "If any exclusion criteria are met, exclude the article. \\\n",
    "Exclusion criteria: {'; '.join(exclusion_criteria_list)}. \\\n",
    "You also need to describe the reason for including or excluding the paper. \\\n",
    "Use JSON format with no additional description or context. \\\n",
    "The data schema should be like this: {json_schema_1st}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d95dfc-b5bf-446b-86e5-155cbbaae6a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_responses(batch, response_text):\n",
    "    resp = json.loads(response_text).get('gpt_decision')\n",
    "    if len(resp) != len(batch):\n",
    "        print('Missing ', len(resp) - len(batch), 'papers')\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def missing_responses(batch, response_text):\n",
    "    resp_df = pd.DataFrame(json.loads(response_text).get('gpt_decision'))\n",
    "    title_set = list(resp_df['Title'])\n",
    "    indxes = []\n",
    "    for item in range(0, len(batch)):    \n",
    "        full = batch[item].split('\\n ')[0]\n",
    "        title = batch[item].split('\\n ')[0].split('Title: ')[1]        \n",
    "        if title not in title_set:\n",
    "            indxes.append(item)\n",
    "            print('Missing the decision of: ', title)\n",
    "    return indxes\n",
    "    \n",
    "    \n",
    "    \n",
    "def send_batched_requests(messages, prompt, batched_responses= [], model=gpt_model, batch_size=25):\n",
    "    # Function to send batched requests\n",
    "     \n",
    "\n",
    "    # Split messages into batches\n",
    "    for i in range(0, len(messages), batch_size):\n",
    "        batch = messages[i:i + batch_size]        \n",
    "        \n",
    "        string = '\\n'.join(batch)                \n",
    "        \n",
    "        prompt_s = prompt + string        \n",
    "        \n",
    "        encoding = tiktoken.encoding_for_model(gpt_model)\n",
    "        token_count = len(encoding.encode(prompt_s))        \n",
    "        \n",
    "        print(f\"The input text contains {token_count} tokens.\")\n",
    "\n",
    "        # Send request to the API\n",
    "        try:\n",
    "            response = requisition_chat(gpt_model, prompt_s)        \n",
    "            \n",
    "            # Append the response to batched_responses \n",
    "            responses_text = response.choices[0].message.content        \n",
    "\n",
    "            token_o = len(encoding.encode(responses_text))\n",
    "            print(f\"The output text contains {token_o} tokens.\")\n",
    "\n",
    "            # if check_responses(batch, responses_text):\n",
    "            batched_responses.append(responses_text)                                \n",
    "\n",
    "            if check_responses(batch, responses_text) is False:\n",
    "                # Re-query the model for missing responses\n",
    "                time.sleep(1)  # Sleep to avoid rate limit            \n",
    "                idx_partial_responses = missing_responses(batch, responses_text)            \n",
    "                print('Re-query the model for missing responses')\n",
    "                batched_responses = send_batched_requests(batch[idx_partial_responses], prompt, batched_responses, gpt_model, batch_size)     \n",
    "        except:            \n",
    "            pass\n",
    "               \n",
    "        \n",
    "        \n",
    "        # Rate limiting to avoid hitting API limits\n",
    "        time.sleep(2)  # Adjust based on your rate limit\n",
    "\n",
    "    return batched_responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f090f744-ba33-46e1-a31e-a925b78e11ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "responses = send_batched_requests(messages, prompt, batched_responses= [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0d3fbd-338f-4f1a-bc09-b0dc565395fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "l_responses = []\n",
    "for response in responses:\n",
    "    l_responses.append(json.loads(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203e862d-43d5-4ae8-aba5-e9b490f69d6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_decision = pd.DataFrame()\n",
    "a = 0\n",
    "for i in range(0, len(l_responses)):\n",
    "    a +=  len(l_responses[i].get('gpt_decision'))\n",
    "    df_decision = pd.concat([df_decision, pd.DataFrame(l_responses[i].get('gpt_decision'))])\n",
    "df_decision.reset_index(inplace = True, drop=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587beb7e-c4bd-4958-bfdd-6a3a9d397774",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_decision = df_decision[['Title', 'Decision', 'Reason']]\n",
    "df_decision = df_decision.rename(columns={'Title': 'title', 'Decision':'decision', 'Reason': 'reason'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f71164d-b05b-408d-927d-3cc9e8a43dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_decision.title.duplicated()[df_decision.title.duplicated() == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4fb9df-5319-458f-be72-0f8e7c77b717",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_decision.drop_duplicates(keep='first', inplace=True)\n",
    "df_decision.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a784ac52-696f-4a83-931d-e037c29e4865",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_decision.to_csv('1st_decision.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5575b84-f47f-4533-a37d-d2c4e0af34ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2193f4d-fe67-45aa-821a-e43611331076",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mask = df_decision['title'].str.contains('combining antibody tests and taking into acc')\n",
    "result = df_decision[mask]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9e076e-16c9-4190-8ac9-7a5f3316d80c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.loc[papers_].Title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d95e9d-0dd6-4b29-a709-74b64fc48377",
   "metadata": {},
   "source": [
    "## Second screening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd9185c-daad-43e7-a83b-2875dd60e4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_decision = pd.read_csv('1st_decision.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2f3d3a-cfc2-42c6-8cf3-6befea6e3c68",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Set max column width to None to display full title\n",
    "pd.set_option('display.max_colwidth', 50) \n",
    "pd.set_option('display.width', 1000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79de2ff9-f872-4f4d-b29b-026405644e61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "null_mask = df_decision.isnull().any(axis=1)\n",
    "df_decision[null_mask].title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906f8ea8-7f68-46ab-a0e0-f07174a02794",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "included_papers = df_decision[df_decision.decision == 'include'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b25545-ec65-44eb-a1ca-af6a162bf33a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "included_papers.rename(columns={'title': 'Title'}, inplace=True)\n",
    "included_papers['Title'] = included_papers['Title'].str.rstrip('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cb0cf7-1203-4b16-8b1b-a68a339b7a6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "included_papers['Title'] = included_papers['Title'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b674b2a-d8e9-497e-a234-e64cd2724a29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "included_papers = included_papers.merge(df[['PMID', 'Title', 'Abstract', 'Country', 'PubYear']], how='left', on='Title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6e7bde-6366-4f2b-9e83-70332be60f4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "null_mask = included_papers.isnull().any(axis=1)\n",
    "included_papers = included_papers[~null_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9978433-8f30-4a93-b495-730c01fbf78b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "included_papers.PMID = included_papers.PMID.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1695d277-e23b-44f9-92e0-f1d88e989f34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "included_papers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
